<p align="center">
  <img src="docs/logo.png" alt="RRI Logo" width="120" />
</p>

<h1 align="center">üî¨ RRI ‚Äî Research & Repository Intelligence</h1>

<p align="center">
  <em>An AI-powered OSINT platform for automated research paper discovery, GitHub repository tracking, and intelligent knowledge management.</em>
</p>

<p align="center">
  <a href="#-features"><img src="https://img.shields.io/badge/Features-12+-blue?style=for-the-badge" alt="Features" /></a>
  <a href="#-tech-stack"><img src="https://img.shields.io/badge/FastAPI-009688?style=for-the-badge&logo=fastapi&logoColor=white" alt="FastAPI" /></a>
  <a href="#-tech-stack"><img src="https://img.shields.io/badge/Next.js_14-000000?style=for-the-badge&logo=next.js&logoColor=white" alt="Next.js" /></a>
  <a href="#-tech-stack"><img src="https://img.shields.io/badge/Python-3.11+-3776AB?style=for-the-badge&logo=python&logoColor=white" alt="Python" /></a>
  <a href="#-tech-stack"><img src="https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white" alt="Docker" /></a>
  <a href="LICENSE"><img src="https://img.shields.io/badge/License-MIT-green?style=for-the-badge" alt="License" /></a>
</p>

<p align="center">
  <a href="#-quick-start">Quick Start</a> ‚Ä¢
  <a href="#-features">Features</a> ‚Ä¢
  <a href="#-architecture">Architecture</a> ‚Ä¢
  <a href="#-cli-tool">CLI Tool</a> ‚Ä¢
  <a href="#-screenshots">Screenshots</a> ‚Ä¢
  <a href="#-api-reference">API Reference</a> ‚Ä¢
  <a href="#-contributing">Contributing</a>
</p>

---

## üìñ Overview

**RRI (Research & Repository Intelligence)** is a full-stack, self-hosted platform designed for researchers, engineers, and teams who want to **automate the discovery and analysis** of academic papers, open-source repositories, and AI/ML community discussions ‚Äî all in one place.

RRI continuously collects data from **11+ sources**, processes it with NLP pipelines, indexes everything into a **vector database** for semantic search, and provides an **AI chat interface** (RAG) so you can ask questions about your research corpus in natural language.

### üéØ Who is RRI for?

| Audience | Use Case |
|:---------|:---------|
| üéì **Researchers** | Track new papers in your field, discover related work, get AI-generated summaries |
| üë©‚Äçüíª **ML Engineers** | Monitor trending GitHub repos, HuggingFace models, and community discussions |
| üè¢ **Research Teams** | Centralized knowledge base with document chat, bookmarks, and weekly digests |
| üìä **Tech Leads** | Tech radar, trend analysis, and automated intelligence reports |

---

## ‚ú® Features

### üìÑ Multi-Source Data Collection

RRI automatically collects and aggregates data from **11+ academic and developer sources**:

| Source | Type | Data Collected |
|:-------|:-----|:---------------|
| üî¨ **ArXiv** | Papers | Pre-prints with abstracts, categories, authors |
| üìö **Semantic Scholar** | Papers | Citations, references, influence scores |
| üåê **OpenAlex** | Papers | Open-access metadata, concepts, institutions |
| üíª **Papers With Code** | Papers + Code | Paper-code links, benchmarks, tasks |
| üêô **GitHub** | Repositories | Stars, forks, languages, topics, README |
| ü§ó **HuggingFace** | Models + Papers | Model cards, downloads, daily papers |
| üìù **OpenReview** | Peer Reviews | ICLR/NeurIPS reviews, ratings, decisions |
| üü† **Hacker News** | Discussions | AI/ML posts, scores, comments |
| ‚úçÔ∏è **Dev.to** | Blog Posts | Technical articles, tags, reactions |
| üêò **Mastodon** | Social Posts | Research community discussions |
| üîó **Lemmy** | Forum Posts | Federated community discussions |

### üîç Semantic Search

- **Vector-based search** powered by [Qdrant](https://qdrant.tech/) and [BGE embeddings](https://huggingface.co/BAAI/bge-base-en-v1.5)
- Search across **papers and repositories** simultaneously
- Relevance scoring with percentage match display
- Filter results by type (Papers / Repos / All)

### ü§ñ AI-Powered Chat (RAG)

- **Retrieval-Augmented Generation** pipeline with context-aware answers
- Dual LLM support: **Ollama** (local, private) + **OpenAI GPT-4o** (cloud)
- **Document Chat**: Upload PDFs, DOCX, PPTX ‚Üí ask questions about your documents
- **Repo Ingestion**: Ingest entire GitHub repositories via [gitingest](https://github.com/cyclotruc/gitingest) ‚Üí chat about code
- Full context mode vs. RAG retrieval mode per conversation
- Conversation history with multi-turn support

### üìä Analytics & Trending

- **Papers Overview**: Category distribution (donut chart), yearly publication trends (bar chart)
- **Trending Papers & Repos**: Filterable by period (day/week/month), category, language
- **Tech Radar**: Auto-generated technology trend analysis
- **HuggingFace Dashboard**: Model rankings, download stats, task distribution
- **Community Keywords**: Trending topics across platforms with keyword analysis

### üìã Knowledge Management

- **Bookmarks & Folders**: Organize papers and repos into custom folders
- **My Library**: Personal document collection with folder tree
- **Weekly Reports**: Auto-generated research digest summaries
- **Paper-Code Linking**: Automatically match papers to their implementations
- **Citation Enrichment**: Bulk update citation counts from Semantic Scholar

### üîê Authentication & Multi-User

- JWT-based authentication with user registration/login
- Per-user document libraries, bookmarks, and conversations
- Role-based access to AI chat features

### üåô Modern UI/UX

- **Dark/Light theme** toggle with smooth transitions
- **Responsive design** with glassmorphism effects and micro-animations
- **Interactive charts** built with Recharts
- **Knowledge graph** visualization with react-force-graph-2d
- Global search bar with keyboard shortcut (`/`)

---

## üèó Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                           FRONTEND (Next.js 14)                        ‚îÇ
‚îÇ  Dashboard ‚îÇ Papers ‚îÇ Repos ‚îÇ Search ‚îÇ Trending ‚îÇ Community ‚îÇ AI Chat  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                               ‚îÇ REST API
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                          BACKEND (FastAPI)                             ‚îÇ
‚îÇ                                                                        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ--‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ  API     ‚îÇ  ‚îÇ Collectors‚îÇ  ‚îÇProcessors ‚îÇ  ‚îÇ   LLM    ‚îÇ  ‚îÇ   RAG   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ Routers  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ  Router  ‚îÇ  ‚îÇPipeline ‚îÇ ‚îÇ
‚îÇ  ‚îÇ (15)     ‚îÇ  ‚îÇ ArXiv     ‚îÇ  ‚îÇEmbedding  ‚îÇ  ‚îÇ          ‚îÇ  ‚îÇ         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ          ‚îÇ  ‚îÇ GitHub    ‚îÇ  ‚îÇClassifier ‚îÇ  ‚îÇ  Ollama  ‚îÇ  ‚îÇRetriever‚îÇ ‚îÇ
‚îÇ  ‚îÇ Papers   ‚îÇ  ‚îÇ Semantic  ‚îÇ  ‚îÇSummarizer ‚îÇ  ‚îÇ  OpenAI  ‚îÇ  ‚îÇReranker ‚îÇ ‚îÇ
‚îÇ  ‚îÇ Repos    ‚îÇ  ‚îÇ Scholar   ‚îÇ  ‚îÇEntity     ‚îÇ  ‚îÇ          ‚îÇ  ‚îÇGenerator‚îÇ ‚îÇ
‚îÇ  ‚îÇ Search   ‚îÇ  ‚îÇ OpenAlex  ‚îÇ  ‚îÇExtractor  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ  ‚îÇ Trending ‚îÇ  ‚îÇ PwC       ‚îÇ  ‚îÇPaperCode  ‚îÇ                            ‚îÇ
‚îÇ  ‚îÇ Chat     ‚îÇ  ‚îÇ HF        ‚îÇ  ‚îÇLinker     ‚îÇ                            ‚îÇ
‚îÇ  ‚îÇ Docs     ‚îÇ  ‚îÇ OpenReview‚îÇ  ‚îÇTechRadar  ‚îÇ                            ‚îÇ
‚îÇ  ‚îÇ Community‚îÇ  ‚îÇ HN/Dev.to ‚îÇ  ‚îÇTrending   ‚îÇ                            ‚îÇ
‚îÇ  ‚îÇ Reports  ‚îÇ  ‚îÇ Mastodon  ‚îÇ  ‚îÇAnalyzer   ‚îÇ                            ‚îÇ
‚îÇ  ‚îÇ Auth     ‚îÇ  ‚îÇ Lemmy     ‚îÇ  ‚îÇ           ‚îÇ                            ‚îÇ
‚îÇ  ‚îÇ Bookmarks‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ           ‚îÇ                            ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ-‚îÄ‚îÄ‚îÄ‚îò                            ‚îÇ
‚îÇ                                                                        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ                    WORKER LAYER (Celery + Redis)                ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Periodic data collection    ‚Ä¢ Embedding generation           ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Citation enrichment         ‚Ä¢ Report generation              ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                               ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ                      ‚îÇ                      ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  PostgreSQL  ‚îÇ  ‚îÇ     Qdrant            ‚îÇ  ‚îÇ    Redis     ‚îÇ
‚îÇ  (Relational ‚îÇ  ‚îÇ  (Vector Database)    ‚îÇ  ‚îÇ   (Cache &   ‚îÇ
‚îÇ   Storage)   ‚îÇ  ‚îÇ  Papers + Repos +     ‚îÇ  ‚îÇ  Task Queue) ‚îÇ
‚îÇ              ‚îÇ  ‚îÇ  Documents embeddings ‚îÇ  ‚îÇ              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üíª CLI Tool

RRI includes a built-in CLI (`rri`) for running OSINT tasks directly from the terminal ‚Äî no browser needed.

### Usage

#### Docker (Recommended)

Since the project runs via Docker, use `docker exec` to run CLI commands:

```bash
# Show help
docker exec rri-app-1 rri --help

# Shorthand: create an alias (add to your ~/.zshrc or ~/.bashrc)
alias rri='docker exec rri-app-1 rri'

# Then use directly
rri collect arxiv --query "LLM" --max-results 10
```

> **Note:** For interactive commands like `rri chat`, you **must** use the `-it` flag:
> ```bash
> docker exec -it rri-app-1 rri chat
> ```

#### Local (without Docker)

If you have the project installed locally with a virtual environment:

```bash
source .venv/bin/activate
pip install -e .
rri --help
```

> When running locally, RRI automatically detects it's outside Docker and converts internal hostnames (ollama, postgres, qdrant, redis) to `localhost`, so it connects to Docker services via exposed ports.

### Available Commands

```
rri collect   Collect papers, models, and repos from various sources
rri search    Search papers, vectors, and repos
rri analyze   Analyze papers with LLM
rri export    Export reports and data
rri chat      Interactive RAG-powered chat (REPL)
```

### `rri collect` ‚Äî Data Collection

```bash
# Collect papers from ArXiv
rri collect arxiv --query "LLM" --category cs.AI --days 7 --max-results 100

# Collect papers from OpenAlex
rri collect openalex --query "transformer" --from-year 2024 --max-results 50

# Collect models from HuggingFace
rri collect huggingface --query "llm" --type models --max-results 20

# Collect datasets from HuggingFace
rri collect huggingface --query "instruction" --type datasets --max-results 20

# Ingest a GitHub repository
rri collect repo https://github.com/user/repo
```

<details>
<summary>Docker equivalent</summary>

```bash
docker exec rri-app-1 rri collect arxiv --query "LLM" --category cs.AI --days 7 --max-results 100
docker exec rri-app-1 rri collect openalex --query "transformer" --from-year 2024 --max-results 50
docker exec rri-app-1 rri collect huggingface --query "llm" --type models --max-results 20
docker exec rri-app-1 rri collect repo https://github.com/user/repo
```
</details>

**Options:**
- `--save-db` ‚Äî Save collected data to database (default: off for ArXiv)
- `--output PATH` ‚Äî Custom output directory (default: `./reports/`)

### `rri search` ‚Äî Search

```bash
# Search papers in database (full-text)
rri search papers "attention mechanism" --limit 20 --sort-by citations

# Semantic vector search across papers
rri search vector "multi-modal RAG pipeline" --limit 10 --collection papers

# Search repositories
rri search repos "llm inference" --limit 10
```

<details>
<summary>Docker equivalent</summary>

```bash
docker exec rri-app-1 rri search papers "attention mechanism" --limit 20 --sort-by citations
docker exec rri-app-1 rri search vector "multi-modal RAG pipeline" --limit 10 --collection papers
docker exec rri-app-1 rri search repos "llm inference" --limit 10
```
</details>

### `rri analyze` ‚Äî LLM-Powered Analysis

```bash
# Analyze a single paper by ArXiv ID (uses local Ollama by default)
rri analyze paper 2401.12345

# Analyze with cloud LLM (OpenAI) and save to database
rri analyze paper 2401.12345 --cloud --save-db

# Batch analyze papers matching a query
rri analyze batch "LLM reasoning" --max-results 10 --category cs.AI
```

<details>
<summary>Docker equivalent</summary>

```bash
docker exec rri-app-1 rri analyze paper 2401.12345
docker exec rri-app-1 rri analyze paper 2401.12345 --cloud --save-db
docker exec rri-app-1 rri analyze batch "LLM reasoning" --max-results 10 --category cs.AI
```
</details>

Each analysis produces: summary, topic classification, keyword extraction, and entity extraction (methods, datasets, metrics, tools). Results are saved as Markdown + JSON in `./reports/`.

### `rri export` ‚Äî Export Data

```bash
# Generate a weekly research report
rri export report --period weekly --format md

# Export papers as CSV
rri export papers --query "LLM" --limit 50 --format csv

# Export papers as JSON or Markdown
rri export papers --query "transformer" --format json
rri export papers --format md --output ./my-export/papers.md
```

<details>
<summary>Docker equivalent</summary>

```bash
docker exec rri-app-1 rri export report --period weekly --format md
docker exec rri-app-1 rri export papers --query "LLM" --limit 50 --format csv
docker exec rri-app-1 rri export papers --query "transformer" --format json
```
</details>

### `rri chat` ‚Äî Interactive RAG Chat

```bash
# Start chat with local LLM (Ollama)
rri chat

# Start chat with cloud LLM (OpenAI)
rri chat --cloud

# Disable reranking for faster responses
rri chat --no-rerank

# Search only specific collections
rri chat --collection papers                          # Papers only
rri chat --collection repositories                    # Repos only
rri chat --collection papers --collection repositories # Papers + Repos
```

<details>
<summary>Docker equivalent (requires -it flag)</summary>

```bash
docker exec -it rri-app-1 rri chat
docker exec -it rri-app-1 rri chat --cloud
docker exec -it rri-app-1 rri chat --no-rerank
docker exec -it rri-app-1 rri chat --collection papers
```
</details>

Type your question and press Enter. The system retrieves relevant papers/repos from the vector database and generates answers with citations. Sources are displayed with type icons:

- `[Paper]` ‚Äî Academic papers (ArXiv, OpenAlex, etc.)
- `[Repo]` ‚Äî GitHub repositories
- `[Chunk]` ‚Äî Document chunks from ingested files

Type `quit` to exit.

> **Note:** All output files (JSON, Markdown, CSV) are saved to `./reports/` by default. Use `--output` to specify a custom path.

---

## üì∏ Screenshots

### LandingPage

![LandingPage](docs/screenshots/landingpage.png)


### Dashboard

![Dashboard](docs/screenshots/dashboard.png)

### Papers ‚Äî Overview & Analytics

![Papers Overview](docs/screenshots/papers-overview.png)

### Papers ‚Äî Browse & Filter

![Papers Browse](docs/screenshots/papers-browse.png)

### Semantic Search

![Semantic Search](docs/screenshots/search.png)

### AI Chat (RAG)

![AI Chat](docs/screenshots/chat.png)

### Trending

![Trending](docs/screenshots/trending.png)

### Community & OpenReview

![Community](docs/screenshots/community.png)

### HuggingFace Models

![HuggingFace](docs/screenshots/huggingface.png)

---

## üõ† Tech Stack

### Backend
| Technology | Purpose |
|:-----------|:--------|
| [FastAPI](https://fastapi.tiangolo.com/) | Async REST API framework |
| [SQLAlchemy 2.0](https://www.sqlalchemy.org/) | Async ORM with PostgreSQL |
| [Celery](https://docs.celeryq.dev/) | Distributed task queue |
| [Qdrant](https://qdrant.tech/) | Vector similarity search engine |
| [Sentence Transformers](https://www.sbert.net/) | BGE text embeddings |
| [Ollama](https://ollama.com/) | Local LLM inference (Llama 3) |
| [OpenAI API](https://platform.openai.com/) | Cloud LLM (GPT-4o) |
| [Alembic](https://alembic.sqlalchemy.org/) | Database migrations |
| [Pydantic v2](https://docs.pydantic.dev/) | Data validation & settings |

### Frontend
| Technology | Purpose |
|:-----------|:--------|
| [Next.js 14](https://nextjs.org/) | React framework (App Router) |
| [TypeScript](https://www.typescriptlang.org/) | Type-safe JavaScript |
| [TailwindCSS](https://tailwindcss.com/) | Utility-first styling |
| [Recharts](https://recharts.org/) | Data visualization charts |
| [react-force-graph-2d](https://github.com/vasturiano/react-force-graph) | Knowledge graph visualization |
| [Lucide React](https://lucide.dev/) | Icon library |
| [Axios](https://axios-http.com/) | HTTP client |

### Infrastructure
| Technology | Purpose |
|:-----------|:--------|
| [Docker Compose](https://docs.docker.com/compose/) | Multi-container orchestration |
| [PostgreSQL 16](https://www.postgresql.org/) | Relational database |
| [Redis 7](https://redis.io/) | Caching & Celery message broker |
| [Qdrant](https://qdrant.tech/) | Vector embeddings storage |
| [Ollama](https://ollama.com/) | Self-hosted LLM runtime |

---

## üöÄ Quick Start

### Prerequisites

- **Docker** & **Docker Compose** (v2.0+)
- **Git**
- *(Optional)* GitHub Personal Access Token for higher API rate limits
- *(Optional)* OpenAI API key for cloud LLM features

### 1. Clone the Repository

```bash
git clone https://github.com/nhdandz/ResearchRover.git
cd RRI
```

### 2. Configure Environment

```bash
cp .env.example .env
```

Edit `.env` with your API keys:

```env
# Required
GITHUB_TOKEN=ghp_your_github_token

# Optional ‚Äî improves functionality
SEMANTIC_SCHOLAR_API_KEY=your_key
HUGGINGFACE_TOKEN=hf_your_token
OPENAI_API_KEY=sk-your_key

# LLM Settings
LOCAL_LLM_URL=http://ollama:11434
LOCAL_LLM_MODEL=llama3:8b-instruct-q4_K_M
CLOUD_LLM_MODEL=gpt-4o

# Embedding
EMBEDDING_MODEL=BAAI/bge-base-en-v1.5
```

### 3. Start All Services

```bash
make up
```

This launches **8 containers**: app, worker, beat, postgres, redis, qdrant, ollama, frontend.

### 4. Run Database Migrations

```bash
make migrate
```

### 5. Pull the LLM Model (for local AI Chat)

```bash
make pull-model
```

### 6. (Optional) Seed Initial Data

```bash
make seed
```

### 7. Access the Application

| Service | URL |
|:--------|:----|
| üåê **Frontend** | [http://localhost:3000](http://localhost:3000) |
| ‚ö° **Backend API** | [http://localhost:8000](http://localhost:8000) |
| üìñ **API Docs (Swagger)** | [http://localhost:8000/docs](http://localhost:8000/docs) |
| üîç **Qdrant Dashboard** | [http://localhost:6333/dashboard](http://localhost:6333/dashboard) |

---

## ‚öôÔ∏è Available Commands

### Make Commands

```bash
make up              # Start all services (docker-compose up -d)
make down            # Stop all services
make logs            # Stream logs from all containers
make migrate         # Run Alembic database migrations
make migrate-create  # Create new migration (msg="description")
make seed            # Seed initial demo data
make init-qdrant     # Initialize Qdrant vector collections
make pull-model      # Download Ollama LLM model
make test            # Run tests with coverage
make lint            # Run ruff linter
make format          # Auto-format code with ruff
```

### CLI via Docker

```bash
docker exec rri-app-1 rri --help                              # Show CLI help
docker exec rri-app-1 rri collect --help                       # Show collect subcommands
docker exec rri-app-1 rri collect arxiv --query "LLM" --max-results 10
docker exec rri-app-1 rri search vector "RAG pipeline" --limit 5
docker exec rri-app-1 rri analyze paper 2401.12345
docker exec rri-app-1 rri export report --period weekly --format md
docker exec -it rri-app-1 rri chat                             # Interactive RAG chat (requires -it)
docker exec -it rri-app-1 rri chat --collection papers         # Chat with papers only
```

---

## üì° API Reference

RRI exposes a comprehensive REST API with auto-generated [Swagger docs](http://localhost:8000/docs).

### Core Endpoints

| Module | Endpoint | Description |
|:-------|:---------|:------------|
| **Auth** | `POST /auth/register` | User registration |
| | `POST /auth/login` | JWT login |
| **Papers** | `GET /papers/` | List/filter/sort papers |
| | `GET /papers/{id}` | Paper detail with metadata |
| | `GET /papers/stats` | Analytics (category, year distribution) |
| | `POST /papers/collect` | Trigger paper collection job |
| | `POST /papers/enrich-citations` | Enrich citation counts |
| **Repos** | `GET /repos/` | List/filter repositories |
| | `GET /repos/{id}` | Repo detail |
| **Search** | `GET /search/?q=...` | Semantic vector search |
| **Trending** | `GET /trending/papers` | Trending papers by period |
| | `GET /trending/repos` | Trending repos by period |
| | `GET /trending/tech-radar` | Technology trend analysis |
| **HuggingFace** | `GET /trending/hf/models` | HF model rankings |
| | `GET /trending/hf/papers` | Daily HF papers |
| **Community** | `GET /community/posts` | Multi-platform posts |
| | `GET /community/discussions` | GitHub discussions |
| | `GET /community/openreview` | OpenReview papers + reviews |
| **AI Chat** | `POST /chat/` | RAG-powered Q&A |
| | `POST /chat/documents/embed` | Embed documents for chat |
| | `POST /chat/documents/embed-repos` | Ingest GitHub repos |
| **Documents** | `GET /documents/` | User document library |
| | `POST /documents/upload` | Upload PDF/DOCX/PPTX |
| **Bookmarks** | `POST /bookmarks/` | Bookmark papers/repos |
| | `GET /bookmarks/folders` | Folder management |
| **Reports** | `GET /reports/weekly` | Weekly research digest |

---

## üìÅ Project Structure

```
RRI/
‚îú‚îÄ‚îÄ üìÇ frontend/                 # Next.js 14 frontend
‚îÇ   ‚îú‚îÄ‚îÄ app/                     # App Router pages
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ page.tsx             #   Dashboard
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ papers/              #   Papers (overview + browse)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ repos/               #   Repositories
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ search/              #   Semantic search
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ trending/            #   Trending analytics
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ huggingface/         #   HuggingFace models
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ community/           #   Community posts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ openreview/          #   OpenReview papers
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chat/                #   AI Chat (RAG)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ my-library/          #   Personal library
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ reports/             #   Weekly reports
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ login/ & register/   #   Authentication
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ layout.tsx           #   Root layout + TopNav
‚îÇ   ‚îú‚îÄ‚îÄ components/              # Reusable components
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ layout/TopNav.tsx    #   Navigation bar
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ AuthProvider.tsx     #   Auth context
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ThemeProvider.tsx    #   Dark/Light theme
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ BookmarkDialog.tsx   #   Bookmark modal
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ FileViewerModal.tsx  #   Document viewer
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ charts/              #   Chart components
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ chat/                #   Chat UI components
‚îÇ   ‚îî‚îÄ‚îÄ lib/                     # API client & utilities
‚îÇ
‚îú‚îÄ‚îÄ üìÇ src/                      # Python backend
‚îÇ   ‚îú‚îÄ‚îÄ main.py                  # FastAPI app factory
‚îÇ   ‚îú‚îÄ‚îÄ cli/                     # CLI tool (rri command)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py              #   Typer app entry point
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ _async.py            #   Async runner helper
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ _context.py          #   Dependency factories
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ _output.py           #   Rich formatting & file writers
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ commands/            #   Command implementations
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ collect.py       #     rri collect (arxiv/openalex/hf/repo)
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ search.py        #     rri search (papers/vector/repos)
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ analyze.py       #     rri analyze (paper/batch)
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ export.py        #     rri export (report/papers)
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ chat.py          #     rri chat (interactive RAG)
‚îÇ   ‚îú‚îÄ‚îÄ api/                     # API layer
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ routers/             #   15 route modules
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ schemas/             #   Pydantic models
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ deps.py              #   Dependencies (auth, db)
‚îÇ   ‚îú‚îÄ‚îÄ collectors/              # Data source collectors
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ arxiv.py             #   ArXiv API
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ github.py            #   GitHub API
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ semantic_scholar.py  #   Semantic Scholar API
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ openalex.py          #   OpenAlex API
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ papers_with_code.py  #   Papers With Code
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ huggingface.py       #   HuggingFace API
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ vietnam/             #   Vietnamese journal sources
‚îÇ   ‚îú‚îÄ‚îÄ processors/              # NLP processing
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ embedding.py         #   BGE embedding generation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ classifier.py        #   Paper classification
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ summarizer.py        #   Text summarization
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ entity_extractor.py  #   Named entity extraction
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ paper_code_linker.py #   Paper‚ÜîCode matching
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tech_analyzer.py     #   Technology analysis
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ trending.py          #   Trend computation
‚îÇ   ‚îú‚îÄ‚îÄ llm/                     # LLM integration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ router.py            #   LLM router (local/cloud)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ollama_client.py     #   Ollama client
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ openai_client.py     #   OpenAI client
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ prompts/             #   Prompt templates
‚îÇ   ‚îú‚îÄ‚îÄ rag/                     # RAG pipeline
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pipeline.py          #   Main RAG orchestrator
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ retriever.py         #   Vector retrieval
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ reranker.py          #   Result reranking
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ generator.py         #   Answer generation
‚îÇ   ‚îú‚îÄ‚îÄ services/                # Business logic
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ paper_service.py     #   Paper operations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ repo_service.py      #   Repository operations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ repo_ingestion.py    #   GitHub repo ingestion
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ text_extractor.py    #   PDF/DOCX/PPTX extraction
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ trending_service.py  #   Trending computations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ export_service.py    #   Data export
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ *_service.py         #   Platform-specific services
‚îÇ   ‚îú‚îÄ‚îÄ storage/                 # Data layer
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ database.py          #   AsyncSession factory
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/              #   20+ SQLAlchemy models
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ repositories/        #   Repository pattern DAOs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cache/               #   Redis caching
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ vector/              #   Qdrant vector store
‚îÇ   ‚îî‚îÄ‚îÄ workers/                 # Background tasks
‚îÇ       ‚îú‚îÄ‚îÄ celery_app.py        #   Celery configuration
‚îÇ       ‚îî‚îÄ‚îÄ tasks/               #   Periodic & on-demand tasks
‚îÇ
‚îú‚îÄ‚îÄ üìÇ migrations/               # Alembic migrations
‚îú‚îÄ‚îÄ üìÇ scripts/                  # Utility scripts
‚îÇ   ‚îú‚îÄ‚îÄ seed_data.py             #   Demo data seeder
‚îÇ   ‚îú‚îÄ‚îÄ index_all.py             #   Bulk vector indexing
‚îÇ   ‚îî‚îÄ‚îÄ tunnel.sh                #   Cloudflare tunnel setup
‚îú‚îÄ‚îÄ üìÇ tests/                    # Test suite
‚îÇ
‚îú‚îÄ‚îÄ docker-compose.yml           # 8-service orchestration
‚îú‚îÄ‚îÄ Dockerfile                   # Backend container
‚îú‚îÄ‚îÄ Makefile                     # Dev commands
‚îú‚îÄ‚îÄ pyproject.toml               # Python dependencies
‚îî‚îÄ‚îÄ .env.example                 # Environment template
```

---

## üîß Configuration

### Environment Variables

| Variable | Required | Description |
|:---------|:--------:|:------------|
| `DATABASE_URL` | ‚úÖ | PostgreSQL connection string |
| `REDIS_URL` | ‚úÖ | Redis connection string |
| `QDRANT_URL` | ‚úÖ | Qdrant server URL |
| `SECRET_KEY` | ‚úÖ | JWT signing key |
| `GITHUB_TOKEN` | ‚úÖ | GitHub API token |
| `SEMANTIC_SCHOLAR_API_KEY` | ‚ùå | Improves paper data |
| `HUGGINGFACE_TOKEN` | ‚ùå | HuggingFace API access |
| `OPENAI_API_KEY` | ‚ùå | Cloud LLM features |
| `LOCAL_LLM_URL` | ‚ùå | Ollama server URL |
| `LOCAL_LLM_MODEL` | ‚ùå | Local LLM model name |
| `CLOUD_LLM_MODEL` | ‚ùå | Cloud LLM model name |
| `EMBEDDING_MODEL` | ‚ùå | Sentence-transformer model |

---

## üîÑ Data Pipeline

```mermaid
graph LR
    A[üì° Data Sources] --> B[üîÑ Collectors]
    B --> C[üß† Processors]
    C --> D[üíæ PostgreSQL]
    C --> E[üîç Qdrant Vectors]
    D --> F[üìä API / Frontend]
    E --> G[üîé Semantic Search]
    E --> H[ü§ñ RAG Chat]
    
    style A fill:#e1f5fe
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#e8f5e9
    style E fill:#fce4ec
    style F fill:#e0f2f1
    style G fill:#fff9c4
    style H fill:#f1f8e9
```

**Collection Cycle:**
1. **Celery Beat** triggers periodic collection tasks (configurable schedule)
2. **Collectors** fetch data from external APIs (ArXiv, GitHub, etc.)
3. **Processors** enrich data: classify, summarize, extract entities, compute embeddings
4. **Storage** persists structured data to PostgreSQL and vectors to Qdrant
5. **Frontend** displays collected data with real-time analytics

---

## üß™ Development

### Running Locally (without Docker)

```bash
# Backend
python -m venv .venv
source .venv/bin/activate
pip install -e ".[dev]"
uvicorn src.main:app --reload --port 8000

# Frontend
cd frontend
npm install
npm run dev
```

### Running Tests

```bash
make test
# or
pytest tests/ -v --cov=src
```

### Code Quality

```bash
make lint     # Check with ruff
make format   # Auto-format with ruff
```

---

## üåê Deployment

### Docker Compose (Recommended)

```bash
# Production deployment
docker-compose up -d

# With Cloudflare Tunnel (for public access)
bash scripts/tunnel.sh
```

### Service Ports

| Service | Port | Protocol |
|:--------|:-----|:---------|
| Frontend | 3000 | HTTP |
| Backend API | 8000 | HTTP |
| PostgreSQL | 5432 | TCP |
| Redis | 6379 | TCP |
| Qdrant | 6333 | HTTP |
| Ollama | 11434 | HTTP |

---

## üó∫ Roadmap

- [ ] üîî Real-time alerting with email/Slack notifications
- [ ] üìà Advanced trend analysis with time-series visualization
- [ ] üåç Multi-language support (Vietnamese paper sources already integrated)
- [ ] üì± Mobile-responsive PWA
- [ ] üîó BibTeX export and Zotero integration
- [ ] üß© Plugin system for custom data sources
- [ ] üìä Comparative analysis dashboards
- [ ] ü§ù Team collaboration features

---

## ü§ù Contributing

Contributions are welcome! Here's how to get started:

1. **Fork** the repository
2. **Create** your feature branch (`git checkout -b feature/amazing-feature`)
3. **Commit** your changes (`git commit -m 'Add amazing feature'`)
4. **Push** to the branch (`git push origin feature/amazing-feature`)
5. **Open** a Pull Request

Please ensure your code follows the existing style and passes lint checks (`make lint`).

---

## üìÑ License

This project is licensed under the **MIT License** ‚Äî see the [LICENSE](LICENSE) file for details.

---

<p align="center">
  <strong>Built with ‚ù§Ô∏è for the research community</strong>
  <br />
  <sub>If you find RRI useful, consider giving it a ‚≠ê on GitHub!</sub>
</p>
